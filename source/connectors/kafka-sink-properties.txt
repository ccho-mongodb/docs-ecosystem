.. _kafka-sink-properties:

=============================================
Kafka Sink Connector Configuration Properties
=============================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Sink Connector Configuration Properties
---------------------------------------

The following settings can be configured in the ``connector.properties`` file.
For an example configuration file see `MongoSinkConnector.properties
<https://github.com/mongodb/mongo-kafka/blob/master/config/MongoSinkConnector.properties>`_.

.. list-table::
   :header-rows: 1
   :stub-columns: 1

   * - Name
     - Description
     - Type
     - Default
     - Valid Values

   * - topics
     - A list of kafka topics for the sink connector.
     - list
     -
     - A non-empty list

   * - connection.uri
     - The connection URI as supported by the official drivers. E.g. mongodb://user@pass@locahost/
     - string
     - mongodb://localhost:27017
     - A valid connection string

   * - database
     - The database for the sink to write.
     - string
     -
     - non-empty string

   * - collection
     - Optional, single sink collection name to write to. If following multiple
       topics then this will be the default collection they are mapped to.
     - string
     - ""
     -

   * - document.id.strategy
     - The IdStrategy class name to use for generating a unique document id
       (_id).
     - string
     - com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
     - An empty string OR A string matching
       ``(\p{javaJavaIdentifierStart}\p{javaJavaIdentifierPart}*\.)*\p{javaJavaIdentifierStart}\p{javaJavaIdentifierPart}*``

   * - delete.on.null.values
     - Whether or not the connector tries to delete documents based on key when
       value is null.
     - boolean
     - false
     -

   * - max.batch.size
     - The maximum number of sink records to possibly batch together for
       processing.
     - int
     - 0
     - [0,...]

   * - max.num.retries
     - How often a retry should be done on write errors.
     - int
     - 3
     - [0,...]

   * - retries.defer.timeout
     - How long in ms a retry should get deferred.
     - into
     - 5000
     - [0,...]

   * - change.data.capture.handler
     - The class name of the CDC handler to use for processing.
     - string
     - ""
     - An empty string OR A string matching
       ``(\p{javaJavaIdentifierStart}\p{javaJavaIdentifierPart}*\.)*\p{javaJavaIdentifierStart}\p{javaJavaIdentifierPart}*``

   * - field.renamer.mapping
     - An inline JSON array with objects describing field name mappings.
       Example:
       [{"oldName":"key.fieldA","newName":"field1"},{"oldName":"value.xyz",
       "newName":"abc"}]
     - string
     - []
     - A valid JSON array

   * - field.renamer.regexp
     - An inline JSON array with objects describing regexp settings. Example:
       [[{"regexp":"^key\\\\..*my.*$","pattern":"my","replace":""},{"regexp":
       "^value\\\\..*$","pattern":"\\\\.","replace":"_"}]
     - string
     - []
     - A valid JSON array


   * - key.projection.list
     - A comma separated list of field names for key projection.
     - string
     - ""
     -

   * - key.projection.type
     - The type of key projection to use.
     - string
     - none
     - [none, blacklist, whitelist]

   * - post.processor.chain
     - A comma separated list of post processor classes to process the data
       before saving to MongoDB.
     - list
     - [ com.mongodb.kafka.connect.sink.processor.DocumentIdAdder ]
     - A list matching: (\p{javaJavaIdentifierStart}\p{javaJavaIdentifierPart}*\.)*\p{javaJavaIdentifierStart}\p{javaJavaIdentifierPart}*

   * - rate.limiting.every.n
     - After how many processed batches the rate limit should trigger (NO rate
       limiting if n=0)
     - int
     - 0
     - [0,...]

   * - rate.limiting.timeout
     - How long in ms processing should wait before continuing processing.
     - int
     - 0
     - [0,...]

   * - value.projection.list
     - A comma separated list of field names for value projection.
     - string
     - ""
     -

   * - value.projection.type
     - The type of value projection to use.
     - string
     - none
     - [none, blacklist, whitelist]

   * - writemodel.strategy
     - The class the handles how build the write models for the sink
       documents.
     - string
     - com.mongodb.kafka.connect.sink.writemodel.strategy.ReplaceOneDefaultStrategy
     - A string matching (\p{javaJavaIdentifierStart}\p{javaJavaIdentifierPart}*\.)*\p{javaJavaIdentifierStart}\p{javaJavaIdentifierPart}*

   * - topic.override.%s.%s
     - The overrides configuration allows for per topic customization of
       configuration. The customized overrides are merged with the default
       configuration, to create the specific configuration for a topic.
       For example, ``topic.override.foo.collection=bar`` will store data
       from the foo topic into the bar collection. 
       .. note::

          All configuration options apart from 'connection.uri' and 
          'topics' are overridable.
     - string
     - ""
     - Topic override

Topic Specific Configuration Settings
-------------------------------------

The MongoDB Kafka Sink Connector, supports sinking data from multiple topics.
However, as data may vary between the topics, individual configurations can
be overriden using the ``topic.override.<topicName>.<configurationName>``
syntax. This allows any individual configuration to be overridden on a per
topic basis.

.. note::

   The ``topics`` and ``connection.uri`` configurations are global and
   *cannot* be overridden.

The following configuration fragments show how to apply different settings for
the ``topicA`` and ``topicC`` topics.

.. code-block:: properties

   # Specific processing settings for 'topicA'

   topic.override.topicA.collection=collectionA
   topic.override.topicA.document.id.strategy=com.mongodb.kafka.connect.sink.processor.id.strategy.UuidStrategy
   topic.override.topicA.post.processor.chain=com.mongodb.kafka.connect.sink.processor.DocumentIdAdder,com.mongodb.kafka.connect.sink.processor.BlacklistValueProjector
   topic.override.topicA.value.projection.type=blacklist
   topic.override.topicA.value.projection.list=k2,k4
   topic.override.topicA.max.batch.size=100

These properties result in the following actions for messages originating
from the ``topicA`` Kafka topic:

- Document identity (``_id`` field) will be given by a generated UUID.
- Value projection will be done using a blacklist approach in order to remove
  fields ``k2`` and ``k4``.
- At most 100 documents will be written to the MongoDB collection
  `collectionA` in one bulk write operation.

Then there are also individual settings for topic ``topicC``:

.. code-block:: properties

   # Specific processing settings for 'topicC'

   topic.override.topicA.collection=collectionC
   topic.override.topicC.document.id.strategy=com.mongodb.kafka.connect.sink.processor.id.strategy.ProvidedInValueStrategy
   topic.override.topicC.post.processor.chain=com.mongodb.kafka.connect.sink.processor.WhitelistValueProjector
   topic.override.topicC.value.projection.type=whitelist
   topic.override.topicC.value.projection.list=k3,k5
   topic.override.topicC.writemodel.strategy=com.mongodb.kafka.connect.sink.writemodel.strategy.UpdateOneTimestampsStrategy

These settings result in the following actions for messages originating from
the ``topicC`` Kafka topic:

- Document identity (``_id`` field) will be taken from the value structure
  of the message.
- Value projection will be done using a whitelist approach to remove only
  retain ``k3`` and ``k5``.
- The chosen write model strategy will keep track of inserted and modified
  timestamps for each written document.

Fallback to Defaults
~~~~~~~~~~~~~~~~~~~~

All default configurations will be used, unless a specific topic override
is configured.

