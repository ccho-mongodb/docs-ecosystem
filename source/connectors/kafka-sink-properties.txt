.. _kafka-sink-properties:

=============================================
Kafka Sink Connector Configuration Properties
=============================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Sink Connector Configuration Properties
---------------------------------------

Refer to the table below to create or migrate a properties file for your
MongoDB Kafka sink connector. See `MongoSinkConnector.properties
<https://github.com/mongodb/mongo-kafka/blob/master/config/MongoSinkConnector.properties>`_
for an example configuration file.

.. list-table::
   :header-rows: 1
   :stub-columns: 1

   * - Name
     - Description
     - Type
     - Default
     - Valid Values

   * - topics
     - A list of Kafka topics for the sink connector.
     - list
     -
     - A non-empty list

   * - connection.uri
     - A :manual:`standard MongoDB connection URI string
       </reference/connection-string/#standard-connection-string-format>`.
       For example: ``mongodb://username:password@localhost/``
     - string
     - ``mongodb://localhost:27017``
     - A valid connection string

   * - database
     - The name of the MongoDB database the sink writes to.
     - string
     -
     - A non-empty string

   * - collection
     - *Optional*. Single sink MongoDB collection name to write to. If
       the sink follows multiple topics, this is the default collection
       they are mapped to.
     - string
     - ``""``
     -

   * - document.id.strategy
     - The IdStrategy class name to use for generating a unique document id
       (_id).
     - string
     - ``com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy``
     - An empty string or a fully qualified Java class name

   * - delete.on.null.values
     - Whether or not the connector tries to delete documents based on key when
       value is null.
     - boolean
     - ``false``
     - ``true`` or ``false``

   * - max.batch.size
     - The maximum number of sink records to possibly batch together for
       processing.
     - int
     - ``0``
     - An integer

   * - max.num.retries
     - How often a retry should be done on write errors.
     - int
     - ``3``
     - An integer

   * - retries.defer.timeout
     - How long in ms a retry should get deferred.
     - int
     - ``5000``
     - An integer

   * - change.data.capture.handler
     - The class name of the CDC handler to use for processing.
     - string
     - ``""``
     - An empty string or a fully qualified Java class name

   * - field.renamer.mapping
     - An inline JSON array with objects describing field name mappings.
       For example:
       ``[{ "oldName":"key.fieldA", "newName":"field1" }, { "oldName":"value.xyz", "newName":"abc" }]``
     - string
     - ``[]``
     - A valid JSON array

   * - field.renamer.regexp
     - An inline JSON array with objects describing regexp settings. For
       example:
       ``[[{"regexp":"^key\\\\..*my.*$","pattern":"my","replace":""},{"regexp":"^value\\\\..*$","pattern":"\\\\.","replace":"_"}]``
     - string
     - ``[]``
     - A valid JSON array

   * - key.projection.list
     - A comma-separated list of field names for key projection.
     - string
     - ``""``
     -

   * - key.projection.type
     - The type of key projection to use.
     - string
     - ``none``
     - ``none``, ``blacklist``, or ``whitelist``

   * - post.processor.chain
     - A comma-separated list of post-processor classes to process the data
       before saving to MongoDB.
     - list
     - ``[ com.mongodb.kafka.connect.sink.processor.DocumentIdAdder ]``
     - A list of fully qualified Java class names

   * - rate.limiting.every.n
     - After how many processed batches the rate limit should trigger (NO rate
       limiting if n=0)
     - int
     - ``0``
     - An integer

   * - rate.limiting.timeout
     - How long in ms processing should wait before continuing processing.
     - int
     - ``0``
     - An integer

   * - value.projection.list
     - A comma-separated list of field names for value projection.
     - string
     - ``""``
     -

   * - value.projection.type
     - The type of value projection to use.
     - string
     - ``none``
     - ``none``, ``blacklist``, or ``whitelist``

   * - writemodel.strategy
     - The class that handles how build the write models for the sink
       documents.
     - string
     - ``com.mongodb.kafka.connect.sink.writemodel.strategy.ReplaceOneDefaultStrategy``
     - A fully qualified Java class name

   * - topic.override.<topicName>.<propertyName>
     - Specifies per-topic configuration overrides. For example:
       ``topic.override.foo.collection=bar`` instructs the connector sink
       to store data from the ``foo`` topic in the ``bar`` collection. See
       :ref:`topic-specific-configuration` for additional examples.

       .. note::

          All configuration options can be specified on a per-topic basis
          except ``connection.uri`` and ``topics``.

     - string
     - ``""``
     - Value specific to the topic override property

.. _topic-specific-configuration:

Topic-Specific Configuration Settings
-------------------------------------

The MongoDB Kafka Sink Connector supports sinking data from multiple topics.
Specify properties specific to a topic using configurations in the
``topic.override.<topicName>.<propertyName>`` format. The properties that
are not overridden will use the global (not topic-specific) settings or
default values.

.. note::

   The ``topics`` property and ``connection.uri`` property are global and
   **cannot** be overridden.

The following examples demonstrate how to apply topic-specific settings to
sink data:

Example: Override Connector Sink Settings on TopicA
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: properties

   topic.override.topicA.collection=collectionA
   topic.override.topicA.document.id.strategy=com.mongodb.kafka.connect.sink.processor.id.strategy.UuidStrategy
   topic.override.topicA.post.processor.chain=com.mongodb.kafka.connect.sink.processor.DocumentIdAdder,com.mongodb.kafka.connect.sink.processor.BlacklistValueProjector
   topic.override.topicA.value.projection.type=blacklist
   topic.override.topicA.value.projection.list=k2,k4
   topic.override.topicA.max.batch.size=100

These properties result in the following actions for messages originating
from the ``topicA`` Kafka topic:

- Generate a UUID to be stored in the ``_id`` field for each new document.
- Omit fields ``k2`` and ``k4`` from the value projection using a blacklist.
- Write documents to the MongoDB collection ``collectionA`` in batches of
  up to 100.

Example: Override Connector Sink Settings on TopicC
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: properties

   topic.override.topicC.collection=collectionC
   topic.override.topicC.document.id.strategy=com.mongodb.kafka.connect.sink.processor.id.strategy.ProvidedInValueStrategy
   topic.override.topicC.post.processor.chain=com.mongodb.kafka.connect.sink.processor.WhitelistValueProjector
   topic.override.topicC.value.projection.type=whitelist
   topic.override.topicC.value.projection.list=k3,k5
   topic.override.topicC.writemodel.strategy=com.mongodb.kafka.connect.sink.writemodel.strategy.UpdateOneTimestampsStrategy

These properties result in the following actions for messages originating
from the ``topicC`` Kafka topic:

- Read the UUID from the Kafka message and store it in the ``_id`` field for
  each new document.
- Include only fields ``k3`` and ``k5`` in the value projection using
  a whitelist.
- Use the write model strategy ``UpdateOneTimestampsStrategy`` that
  records inserted and modified timestamps for each document.
