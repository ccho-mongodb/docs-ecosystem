.. _kafka-sink-properties:

=============================================
Kafka Sink Connector Configuration Properties
=============================================

.. default-domain:: mongodb

.. contents:: On this page
   :local:
   :backlinks: none
   :depth: 1
   :class: singlecol

Sink Connector Configuration Properties
---------------------------------------

Refer to the table below to create or migrate a properties file for your
MongoDB Kafka sink connector. See `MongoSinkConnector.properties
<https://github.com/mongodb/mongo-kafka/blob/master/config/MongoSinkConnector.properties>`_
for an example configuration file.

.. list-table::
   :header-rows: 1
   :stub-columns: 1

   * - Name
     - Description
     - Type
     - Default
     - Valid Values

   * - topics
     - A list of Kafka topics for the sink connector.
     - list
     -
     - A non-empty list.

   * - connection.uri
     - A :manual:`standard MongoDB connection URI string
       </reference/connection-string/#standard-connection-string-format>`.
       For example: ``mongodb://username:password@localhost/``
     - string
     - ``mongodb://localhost:27017``
     - A valid connection string.

   * - database
     - The name of the MongoDB database the sink writes to.
     - string
     -
     - A non-empty string.

   * - collection
     - *Optional*. Single sink MongoDB collection name to write to. If
       the sink follows multiple topics, this is the default collection
       they are mapped to.
     - string
     - ``""``
     -

   * - document.id.strategy
     - The IdStrategy class name to use for generating a unique document id
       (_id).
     - string
     - ``com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy``
     - An empty string or a fully qualified Java class name.

   * - delete.on.null.values
     - Whether or not the connector tries to delete documents based on key when
       value is null.
     - boolean
     - ``false``
     - ``true`` or ``false``.

   * - max.batch.size
     - The maximum number of sink records to possibly batch together for
       processing.
     - int
     - ``0``
     - An integer.

   * - max.num.retries
     - How often a retry should be done on write errors.
     - int
     - ``3``
     - An integer.

   * - retries.defer.timeout
     - How long in ms a retry should get deferred.
     - int
     - ``5000``
     - An integer.

   * - change.data.capture.handler
     - The class name of the CDC handler to use for processing.
     - string
     - ``""``
     - An empty string or a fully qualified Java class name.

   * - field.renamer.mapping
     - An inline JSON array with objects describing field name mappings.
       For example:
       ``[{ "oldName":"key.fieldA", "newName":"field1" }, { "oldName":"value.xyz", "newName":"abc" }]``
     - string
     - ``[]``
     - A valid JSON array.

   * - field.renamer.regexp
     - An inline JSON array with objects describing regexp settings. For
       example:
       ``[[{"regexp":"^key\\\\..*my.*$","pattern":"my","replace":""},{"regexp":"^value\\\\..*$","pattern":"\\\\.","replace":"_"}]``
     - string
     - ``[]``
     - A valid JSON array.

   * - key.projection.list
     - A comma-separated list of field names for key projection.
     - string
     - ``""``
     -

   * - key.projection.type
     - The type of key projection to use.
     - string
     - ``none``
     - ``none``, ``blacklist``, or ``whitelist``.

   * - post.processor.chain
     - A comma-separated list of post-processor classes to process the data
       before saving to MongoDB.
     - list
     - ``[ com.mongodb.kafka.connect.sink.processor.DocumentIdAdder ]``
     - A list of fully qualified Java class names.

   * - rate.limiting.every.n
     - After how many processed batches the rate limit should trigger (NO rate
       limiting if n=0)
     - int
     - ``0``
     - An integer.

   * - rate.limiting.timeout
     - How long in ms processing should wait before continuing processing.
     - int
     - ``0``
     - An integer.

   * - value.projection.list
     - A comma-separated list of field names for value projection.
     - string
     - ``""``
     -

   * - value.projection.type
     - The type of value projection to use.
     - string
     - ``none``
     - ``none``, ``blacklist``, or ``whitelist``

   * - writemodel.strategy
     - The class that handles how build the write models for the sink
       documents.
     - string
     - ``com.mongodb.kafka.connect.sink.writemodel.strategy.ReplaceOneDefaultStrategy``
     - A fully qualified Java class name.

   * - topic.override.<topic>.<property>
     - Specifies per-topic configuration overrides. For example:
       ``topic.override.foo.collection=bar`` instructs the connector sink
       to store data from the ``foo`` topic in the ``bar`` collection.

       .. note::

          All configuration options can be specified on a per-topic basis
          except ``connection.uri`` and ``topics``.

     - string
     - ``""``
     - Value specific to the topic override property.

Topic Specific Configuration Settings
-------------------------------------

The MongoDB Kafka Sink Connector supports sinking data from multiple topics.
However, as data may vary between the topics, individual configurations can
be overriden using the ``topic.override.<topicName>.<configurationName>``
syntax. This allows any individual configuration to be overridden on a per
topic basis.

.. note::

   The ``topics`` and ``connection.uri`` configurations are global and
   *cannot* be overridden.

The following configuration fragments show how to apply different settings for
the ``topicA`` and ``topicC`` topics.

.. code-block:: properties

   # Specific processing settings for 'topicA'

   topic.override.topicA.collection=collectionA
   topic.override.topicA.document.id.strategy=com.mongodb.kafka.connect.sink.processor.id.strategy.UuidStrategy
   topic.override.topicA.post.processor.chain=com.mongodb.kafka.connect.sink.processor.DocumentIdAdder,com.mongodb.kafka.connect.sink.processor.BlacklistValueProjector
   topic.override.topicA.value.projection.type=blacklist
   topic.override.topicA.value.projection.list=k2,k4
   topic.override.topicA.max.batch.size=100

These properties result in the following actions for messages originating
from the ``topicA`` Kafka topic:

- Document identity (``_id`` field) will be given by a generated UUID.
- Value projection will be done using a blacklist approach in order to remove
  fields ``k2`` and ``k4``.
- At most 100 documents will be written to the MongoDB collection
  `collectionA` in one bulk write operation.

Then there are also individual settings for topic ``topicC``:

.. code-block:: properties

   # Specific processing settings for 'topicC'

   topic.override.topicA.collection=collectionC
   topic.override.topicC.document.id.strategy=com.mongodb.kafka.connect.sink.processor.id.strategy.ProvidedInValueStrategy
   topic.override.topicC.post.processor.chain=com.mongodb.kafka.connect.sink.processor.WhitelistValueProjector
   topic.override.topicC.value.projection.type=whitelist
   topic.override.topicC.value.projection.list=k3,k5
   topic.override.topicC.writemodel.strategy=com.mongodb.kafka.connect.sink.writemodel.strategy.UpdateOneTimestampsStrategy

These settings result in the following actions for messages originating from
the ``topicC`` Kafka topic:

- Document identity (``_id`` field) will be taken from the value structure
  of the message.
- Value projection will be done using a whitelist approach to remove only
  retain ``k3`` and ``k5``.
- The chosen write model strategy will keep track of inserted and modified
  timestamps for each written document.

Fallback to Defaults
~~~~~~~~~~~~~~~~~~~~

All default configurations will be used, unless a specific topic override
is configured.

