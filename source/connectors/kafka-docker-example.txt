.. _kafka-docker-example:

======================================
MongoDB Kafka Connector Docker Example
======================================

This guide provides an end-to-end setup of MongoDB and Kafka Connect to
demonstrate the functionality of the MongoDB Kafka Source and Sink
Connectors.

In this example, we create the following Kafka Connectors:

.. list-table::
   :header-rows: 1

   * - Connector
     - Origin
     - Destination

   * - Datagen Connector: **datagen**
     - TODO
     - TODO
       
   * - Sink Connector: **mongo-sink**
     - Kafka topic: ``pageviews``
     - MongoDB collection: ``test.pageviews``

   * - Source Connector: **mongo-source**
     - MongoDB collection: ``test.pageviews``
     - Kafka topic: ``mongo.test.pageviews``

Requirements
------------

TODO: should include requirements for different platforms
* Docker 18.09+
* Docker compose 1.24+
* Linux/Unix-based system

How to Run the Example
----------------------

Clone the repository from GitHub:

.. code-block:: shell

   git clone git@github.com:mongodb/mongo-kafka.git

Change directory to the ``docs`` directory

.. code-block:: shell
 
   cd mongo-kafka/docs/
   
Run the example with the included shell script:

.. code-block:: shell
   
   ./run.sh

The shell script executes the following:

#. Runs the ``docker-compose up`` command
#. Waits for MongoDB, Kafka, Kafka Connect to be ready
#. Registers the Confluent Datagen Connector
#. Registers the MongoDB Kafka Sink Connector
#. Registers the MongoDB Kafka Source Connector
#. Publishes some events to Kafka via the Datagen connector
#. Writes the events to MongoDB  
#. Writes the change stream messages back into Kafka

Once running, open the Kafka control center web UI on http://localhost:9021/

* The ``pageviews`` topic should contain the 10 simple documents added. Each similar to:

  .. code-block:: json

     {"viewtime": {"$numberLong": "81"}, "pageid": "Page_1", "userid": "User_8"}

* The ``mongo.test.pageviews`` should contain the 10 change events. Each similar to:

  .. code-block:: json

      {"_id": {"_data": "<resumeToken>"}, 
       "operationType": "insert", 
       "clusterTime": {"$timestamp": {"t": 1563461814, "i": 4}}, 
       "fullDocument": {"_id": {"$oid": "5d3088b6bafa7829964150f3"}, "viewtime": {"$numberLong": "81"}, "pageid": "Page_1", "userid": "User_8"}, 
       "ns": {"db": "test", "coll": "pageviews"}, 
       "documentKey": {"_id": {"$oid": "5d3088b6bafa7829964150f3"}}}

Examine the collections in MongoDB:

* In your local shell, log into mongo1 through docker:

  .. code-block:: shell

     docker-compose exec mongo1 /usr/bin/mongo
     
* Adding, updating data in ``test.sink`` - will show up as change stream events in the ``mongo.test.sunk`` topic
TODO: ^ why mongo.test.sunk? ^

docker-compose.yml
------------------

The following applications will be installed and started in the docker
container:

* Zookeeper
* Kafka
* Confluent Schema Registry
* Confluent Kafka Connect
* Confluent Control Center
* Confluent KSQL Server
* Kafka Rest Proxy
* Kafka Topics UI
* MongoDB - a 3 node replicaset
