.. _kafka-docker-example:

======================================
MongoDB Kafka Connector Docker Example
======================================

This guide provides an end-to-end setup of MongoDB and Kafka Connect to
demonstrate the functionality of the MongoDB Kafka Source and Sink
Connectors.

In this example, we use the following data flows:

.. list-table::
   :header-rows: 1

   * - Connector
     - Origin
     - Destination

   * - Datagen Connector: **datagen**
     - TODO
     - TODO
       
   * - Sink Connector: **mongo-sink**
     - Kafka topic: ``pageviews``
     - MongoDB collection: ``test.pageviews``

   * - Source Connector: **mongo-source**
     - MongoDB collection: ``test.pageviews``
     - Kafka topic: ``mongo.test.pageviews``

Requirements
------------

TODO: should include requirements for different platforms
* Docker 18.09+
* Docker compose 1.24+
* *nix system

How to Run the Example
----------------------

To run the example: ``./run.sh`` which will:

* Run ``docker-compose up`` 
* Wait for MongoDB, Kafka, Kafka Connect to be ready
* Register the Confluent Datagen Connector
* Register the MongoDB Kafka Sink Connector
* Register the MongoDB Kafka Source Connector
* Publish some events to Kafka via the Datagen connector
* Write the events to MongoDB  
* Write the change stream messages back into Kafka

**Note:** The script expects to be run from within the ``docs`` directory and requires the whole project to be checked out / downloaded. 

Once running, examine the topics in the Kafka control center: http://localhost:9021/

* The ``pageviews`` topic should contain the 10 simple documents added. Each similar to:

  .. code-block:: json

     {"viewtime": {"$numberLong": "81"}, "pageid": "Page_1", "userid": "User_8"}

* The ``mongo.test.pageviews`` should contain the 10 change events. Each similar to:

  .. code-block:: json

      {"_id": {"_data": "<resumeToken>"}, 
       "operationType": "insert", 
       "clusterTime": {"$timestamp": {"t": 1563461814, "i": 4}}, 
       "fullDocument": {"_id": {"$oid": "5d3088b6bafa7829964150f3"}, "viewtime": {"$numberLong": "81"}, "pageid": "Page_1", "userid": "User_8"}, 
       "ns": {"db": "test", "coll": "pageviews"}, 
       "documentKey": {"_id": {"$oid": "5d3088b6bafa7829964150f3"}}}

Examine the collections in MongoDB:

* In your shell run: docker-compose exec mongo1 /usr/bin/mongo
* Adding, updating data in ``test.sink`` - will show up as change stream events in the ``mongo.test.sunk`` topic
TODO: ^ why mongo.test.sunk? ^

docker-compose.yml
------------------

The following systems will be created:

* Zookeeper
* Kafka
* Confluent Schema Registry
* Confluent Kafka Connect
* Confluent Control Center
* Confluent KSQL Server
* Kafka Rest Proxy
* Kafka Topics UI
* MongoDB - a 3 node replicaset
